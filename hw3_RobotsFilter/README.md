# Задание 3. HBase
Неаккуратный программист Вася неправильно забанил URL-ы в таблице. Какие-то документы, которые должны быть закрыты по robots.txt, оказались открытыми. Какие-то, наоборот - ошибочно забанены. Короче, неразбериха.  
Необходимо привести таблицу с URL-ами в порядок. А именно - синхронизировать с таблицей сайтов.  
Подробности под катом.

### Схема таблиц
В HBase имеются 2 таблицы: webpages и websites.  
Ключи в обоих таблицах - хэш-суммы от URL-а и хоста соответственно. (так гарантируется равномерность заполнения регионов).

*В таблице webpages лежат URL-ы и флаги.*
```
    ключ - MD5(url)  
    единственная CF: docs  
    docs:url - содержит URL документа  
    docs:disabled содержит 'Y' если URL закрыт по robots.txt  
```

*В таблице websites лежат сайты и содержимое robots.txt(\*)*
```
    ключ - MD5(site)  
    единственная CF: info  
    info:site - содержит имя сайта (хост)  
    info:robots содержит robots.txt сайта  
```

## (*) robots.txt
robots.txt для сайтов сгенерирован автоматически.  
Единственной директивой является Disallow - указание, что url-ы попадающие под данное выражение запрещены к выкачке спайдером.  
Используемый синтаксис такой:  

```
    Disallow: /info (запрещает пути, начинающиеся с /info: /info, /info/help.html, ...)  
    Disallow: *forum (запрещает все пути, где есть слово forum: /forum, /attic/forum27/, ...)  
    Disallow: remove.php$ (запрещает все пути, оканчивающиеся на remove.php)  
```

Запись robots может содержать несколько таких директив, разделенных переводом строки (\n).  
Сайт может не содержать поля info:robots. В этом случае все его URL-ы доступны.  

## Пересечение таблиц
В ходе семинара упоминалось, что для HBase, подобно тектовым источника, существует свой MultipleInputFormat - возможность считываения из нескольких таблиц. Используя его, Вы можете считывать одновременно и URL-ы/признаки из таблицы webpages и сайты из таблицы websites. 
Примеры чтения из нескольких таблиц:  
* http://rishavrohitblog.blogspot.ru/2014/09/hbase-mapreduce-on-multiple-input-table.html
* https://gist.github.com/rishav-rohit/1224ae3df5f609083619

## Ожидаемый результат
В таблице webpages URL-ы которые запрещены к выкачке содержат docs:disabled=Y (от слова Yes), разрешенные же - не содержат этого поля.  

## Откуда брать таблицы?
Указанные таблицы webpages и websites конечно же не лежат в HBase - иначе все мы перезаписали бы одну и ту же таблицу (вспомните семинар и hbase shell).  
Вместо этого в Hadoop лежат сохраненные снапшоты этих таблиц: webpages_bak и websites_bak.  
Поэтому перед запуском java-программы Вы должны создать свою, уникальную таблицу из соответствующих snapshot-ов. Например:  
```
$ hbase shell  
$ clone_snapshot 'webpages_bak', 'webpages_jan'  
$ clone_snapshot 'websites_bak', 'websites_jan'  
```
Само-собой, вместо jan используйте свой ник :-)

## Проверка и сроки
Ваш jar-файл будет запускаться следующим образом:  
```
$ hadoop jar path/to/file.jar webpages_tablename websites_tablename
```
(разумеется, таблицы будут существовать на момент запуска).  
Проверка будет производиться сверкой содержимого вашей таблицы webpages с опорной. При правильном решении должно быть полное совпадение.  

## Ограничение на общее времея выполнения
3 минуты (2 редьюсера).